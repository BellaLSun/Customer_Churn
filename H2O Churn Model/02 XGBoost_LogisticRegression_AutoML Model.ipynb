{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {
     "keep": true,
     "summary": true
    }
   },
   "source": [
    "# Customer Churn Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys \n",
    "sys.path.append('model_management')\n",
    "\n",
    "from model_management.sklearn_model import SklearnModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from __future__ import print_function\n",
    "import pandas_profiling\n",
    "\n",
    "# Suppress unwatned warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger(\"requests\").setLevel(logging.WARNING)\n",
    "\n",
    "# Load our favorite visualization library\n",
    "import os\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "import cufflinks as cf\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "# Sign into Plotly with masked, encrypted API key\n",
    "\n",
    "myPlotlyKey = os.environ['SECRET_ENV_BRETTS_PLOTLY_KEY']\n",
    "py.sign_in(username='bretto777',api_key=myPlotlyKey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_datascience": {
     "keep": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load some data\n",
    "churnDF = pd.read_csv('https://trifactapro.s3.amazonaws.com/churn.csv', delimiter=',')\n",
    "churnDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#pandas_profiling.ProfileReport(churnDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churnDF[\"Churn\"] = churnDF[\"Churn\"].replace([True, False],[1,0])\n",
    "churnDF[\"Int'l Plan\"] = churnDF[\"Int'l Plan\"].replace([\"no\",\"yes\"],[0,1])\n",
    "churnDF[\"VMail Plan\"] = churnDF[\"VMail Plan\"].replace([\"no\",\"yes\"],[0,1])\n",
    "churnDF.drop([\"State\", \"Area Code\", \"Phone\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Split data into training and testing frames\n",
    "\n",
    "\n",
    "h2o.init(nthreads=1, max_mem_size=\"768m\")\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, testing = train_test_split(churnDF, train_size=0.8, stratify=churnDF[\"Churn\"], random_state=9)\n",
    "x_train = training.drop([\"Churn\"], axis = 1)\n",
    "y_train = training[\"Churn\"]\n",
    "x_test = testing.drop([\"Churn\"], axis = 1)\n",
    "y_test = testing[\"Churn\"]\n",
    "# fit into H2O\n",
    "train = h2o.H2OFrame(python_obj=training)\n",
    "test = h2o.H2OFrame(python_obj=testing)\n",
    "train[\"Churn\"] = train[\"Churn\"].asfactor()\n",
    "test[\"Churn\"] = test[\"Churn\"].asfactor()\n",
    "# Set predictor and response variables\n",
    "y = \"Churn\"\n",
    "x = train.columns\n",
    "x.remove(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbm = GradientBoostingClassifier(n_estimators=200, \n",
    "                                                           learning_rate=.07,\n",
    "                                                           max_depth=4, \n",
    "                                                           random_state=0).fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_gbm = SklearnModel(model=gbm,\n",
    "                     problem_class='binary_classification',\n",
    "                     description='GBM, 275 trees, learning rate .04, max depth 5',\n",
    "                     name=\"GBM-4\",\n",
    "                     y_test = y_test,\n",
    "                     x_test = x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gbm.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gbm.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR = SklearnModel(model=lr,\n",
    "                     problem_class='binary_classification',\n",
    "                     description='sklearn logistic regression, default settings',\n",
    "                     name=\"LR-2\",\n",
    "                     y_test = y_test,\n",
    "                     x_test = x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {
     "keep": true
    }
   },
   "source": [
    "# Automatic Machine Learning\n",
    "\n",
    "The Automatic Machine Learning (AutoML) function automates the supervised machine learning model training process. The current version of AutoML trains and cross-validates a Random Forest, an Extremely-Randomized Forest, a random grid of Gradient Boosting Machines (GBMs), a random grid of Deep Neural Nets, and a Stacked Ensemble of all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run AutoML until 11 models are built\n",
    "autoModel = H2OAutoML(max_models = 9)\n",
    "autoModel.train(x = x, y = y,\n",
    "          training_frame = train,\n",
    "          validation_frame = test, \n",
    "          leaderboard_frame = test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaders = autoModel.leaderboard\n",
    "leaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {
     "keep": true
    }
   },
   "source": [
    "# Variable Importances\n",
    "Below we plot variable importances as reported by the best performing algo in the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_datascience": {
     "keep": true,
     "summary": true
    }
   },
   "outputs": [],
   "source": [
    "importances = h2o.get_model(leaders[2, 0]).varimp(use_pandas=True)\n",
    "importances = importances.loc[:,['variable','relative_importance']].groupby('variable').mean()\n",
    "importances.sort_values(by=\"relative_importance\", ascending=False).iplot(kind='bar', colors='#5AC4F2', theme='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "bestModel = h2o.get_model(leaders[2, 0])\n",
    "plt = bestModel.partial_plot(data=test, cols=[\"Day Mins\",\"CustServ Calls\",\"Day Charge\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {
     "keep": true,
     "summary": false
    }
   },
   "source": [
    "# Best Model vs the Base Learners\n",
    "This plot shows the ROC curves for the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model0 = np.array(h2o.get_model(leaders[0,0]).roc(xval=True))\n",
    "Model1 = np.array(h2o.get_model(leaders[1,0]).roc(xval=True))\n",
    "Model2 = np.array(h2o.get_model(leaders[2,0]).roc(xval=True))\n",
    "Model3 = np.array(h2o.get_model(leaders[3,0]).roc(xval=True))\n",
    "Model4 = np.array(h2o.get_model(leaders[4,0]).roc(xval=True))\n",
    "Model5 = np.array(h2o.get_model(leaders[5,0]).roc(xval=True))\n",
    "Model6 = np.array(h2o.get_model(leaders[6,0]).roc(xval=True))\n",
    "Model7 = np.array(h2o.get_model(leaders[7,0]).roc(xval=True))\n",
    "Model8 = np.array(h2o.get_model(leaders[8,0]).roc(xval=True))\n",
    "Model9 = np.array(h2o.get_model(leaders[9,0]).roc(xval=True))\n",
    "\n",
    "layout = go.Layout(autosize=False, width=725, height=575,  xaxis=dict(title='False Positive Rate', titlefont=dict(family='Arial, sans-serif', size=15, color='grey')), \n",
    "                                                           yaxis=dict(title='True Positive Rate', titlefont=dict(family='Arial, sans-serif', size=15, color='grey')))\n",
    "\n",
    "traceChanceLine = go.Scatter(x = [0,1], y = [0,1], mode = 'lines+markers', name = 'chance', line = dict(color = ('rgb(136, 140, 150)'), width = 4, dash = 'dash'))\n",
    "Model0Trace = go.Scatter(x = Model0[0], y = Model0[1], mode = 'lines', name = 'Model 0', line = dict(color = ('rgb(26, 58, 126)'), width = 3))\n",
    "Model1Trace = go.Scatter(x = Model1[0], y = Model1[1], mode = 'lines', name = 'Model 1', line = dict(color = ('rgb(156, 190, 241))'), width = 1))\n",
    "Model2Trace = go.Scatter(x = Model2[0], y = Model2[1], mode = 'lines', name = 'Model 2', line = dict(color = ('rgb(156, 190, 241)'), width = 1))\n",
    "Model3Trace = go.Scatter(x = Model3[0], y = Model3[1], mode = 'lines', name = 'Model 3', line = dict(color = ('rgb(156, 190, 241)'), width = 1))\n",
    "Model4Trace = go.Scatter(x = Model4[0], y = Model4[1], mode = 'lines', name = 'Model 4', line = dict(color = ('rgb(156, 190, 241)'), width = 1))\n",
    "Model5Trace = go.Scatter(x = Model5[0], y = Model5[1], mode = 'lines', name = 'Model 5', line = dict(color = ('rgb(156, 190, 241)'), width = 1))\n",
    "Model6Trace = go.Scatter(x = Model6[0], y = Model6[1], mode = 'lines', name = 'Model 6', line = dict(color = ('rgb(156, 190, 241)'), width = 1))\n",
    "Model7Trace = go.Scatter(x = Model7[0], y = Model7[1], mode = 'lines', name = 'Model 7', line = dict(color = ('rgb(156, 190, 241)'), width = 1))\n",
    "Model8Trace = go.Scatter(x = Model8[0], y = Model8[1], mode = 'lines', name = 'Model 8', line = dict(color = ('rgb(156, 190, 241)'), width = 1))\n",
    "Model9Trace = go.Scatter(x = Model9[0], y = Model9[1], mode = 'lines', name = 'Model 9', line = dict(color = ('rgb(156, 190, 241)'), width = 1))\n",
    "\n",
    "fig = go.Figure(data=[Model0Trace,Model1Trace,Model2Trace,Model3Trace,Model4Trace,Model5Trace,Model6Trace,Model8Trace,Model9Trace,traceChanceLine], layout=layout)\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {}
   },
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_datascience": {
     "keep": true
    }
   },
   "outputs": [],
   "source": [
    "cm = h2o.get_model(leaders[1, 0]).confusion_matrix(xval=True)\n",
    "cm = cm.table.as_data_frame()\n",
    "cm\n",
    "confusionMatrix = ff.create_table(cm)\n",
    "confusionMatrix.layout.height=300\n",
    "confusionMatrix.layout.width=800\n",
    "confusionMatrix.layout.font.size=17\n",
    "py.iplot(confusionMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {
     "keep": true
    }
   },
   "source": [
    "# Business Impact Matrix\n",
    "\n",
    "Weighting Predictions With a Dollar Value\n",
    "-   Correctly predicting retain: `+$5`\n",
    "-   Correctly predicting churn: `+$75`\n",
    "-   Incorrectly predicting retain: `-$150`\n",
    "-   Incorrectly predicting churn: `-$1.5`\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_datascience": {
     "keep": true
    }
   },
   "outputs": [],
   "source": [
    "CorrectPredictChurn = cm.loc[1,'1']\n",
    "CorrectPredictChurnImpact = 75\n",
    "cm1 = CorrectPredictChurn*CorrectPredictChurnImpact\n",
    "\n",
    "IncorrectPredictChurn = cm.loc[1,'0']\n",
    "IncorrectPredictChurnImpact = -5\n",
    "cm2 = IncorrectPredictChurn*IncorrectPredictChurnImpact\n",
    "\n",
    "IncorrectPredictRetain = cm.loc[0,'1']\n",
    "IncorrectPredictRetainImpact = -150\n",
    "cm3 = IncorrectPredictRetain*IncorrectPredictRetainImpact\n",
    "\n",
    "CorrectPredictRetain = cm.loc[0,'0']\n",
    "CorrectPredictRetainImpact = 5\n",
    "cm4 = IncorrectPredictRetain*CorrectPredictRetainImpact\n",
    "\n",
    "\n",
    "data_matrix = [['Business Impact', '($) Predicted Churn', '($) Predicted Retain', '($) Total'],\n",
    "               ['($) Actual Churn', cm1, cm3, '' ],\n",
    "               ['($) Actual Retain', cm2, cm4, ''],\n",
    "               ['($) Total', cm1+cm2, cm3+cm4, cm1+cm2+cm3+cm4]]\n",
    "\n",
    "impactMatrix = ff.create_table(data_matrix, height_constant=20, hoverinfo='weight')\n",
    "impactMatrix.layout.height=300\n",
    "impactMatrix.layout.width=800\n",
    "impactMatrix.layout.font.size=17\n",
    "py.iplot(impactMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_datascience": {
     "keep": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Total customers evaluated: 2132\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_datascience": {
     "keep": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Total value created by the model: $\" + str(cm1+cm2+cm3+cm4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_datascience": {
     "keep": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Total value per customer: $\" +str(round(((cm1+cm2+cm3+cm4)/2132),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "# Save the best model\n",
    "\n",
    "#path = h2o.save_model(model=h2o.get_model(leaders[0, 0]), force=True)\n",
    "#os.rename(h2o.get_model(leaders[0, 0]).model_id, \"AutoML-leader\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#LoadedEnsemble = h2o.load_model(path=\"AutoML-leader\")\n",
    "#print(LoadedEnsemble)"
   ]
  }
 ],
 "metadata": {
  "_datascience": {
   "notebookId": 608,
   "post_id": "AVs_WCYcdxOghr0gw_3H"
  },
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
